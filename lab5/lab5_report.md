# Report for the Fourth Laboratory Work

<br><br>
<br><br>

## Contents

- [Objectives](#objectives)
- [Overview](#Overview)
- [Implementation](#implementation)
  - [Lexer functionality](#Lexer-functionality)
  - [Split](#split)
  - [Labelling](#Labelling)
  - [Final Touches](#final-touches)
  - [Results](#results)
- [Conclusion](#conclusion)

## Objectives

1.**Learn about Chomsky Normal Form (CNF) [1].**

2.**Get familiar with the approaches of normalizing a grammar.**


3 **Implement a method for normalizing an input grammar by the rules of CNF.
The implementation needs to be encapsulated in a method with an appropriate signature (also ideally in an appropriate class/type).
The implemented functionality needs executed and tested.**

4 **A BONUS point will be given for the student who will have unit tests that validate the functionality of the project.
Also, another BONUS point would be given if the student will make the aforementioned function to accept any grammar, not only the one from the student's variant.**

## Implementation
### What are chosmki normal expressions?

Chomsky Normal Form (CNF) is a specific way of organizing the production rules of a context-free grammar, which is particularly useful in computational linguistics and computer science, especially in the areas of parsing algorithms and natural language processing. A grammar is in Chomsky Normal Form if all of its production rules satisfy the following conditions:

Binary Productions: Each rule produces exactly two non-terminal symbols. That is, any production rule must be of the form 
ùê¥
‚Üí
ùêµ
ùê∂
A‚ÜíBC, where 
ùê¥
A, 
ùêµ
B, and 
ùê∂
C are non-terminal symbols.
Terminal Productions: Each rule produces exactly one terminal symbol. These rules are of the form 
ùê¥
‚Üí
ùëé
A‚Üía, where 
ùê¥
A is a non-terminal and 
ùëé
a is a terminal symbol.
Start Symbol Productions: Optionally, the start symbol (typically 
ùëÜ
S) may be allowed to produce the empty string (epsilon, denoted as 
ùúñ
œµ). However, this is the only exception that allows for the production of 
ùúñ
œµ, and the start symbol should not appear on the right-hand side of any rule.
The significance of CNF lies in its simplicity and utility. Transforming a context-free grammar into Chomsky Normal Form simplifies the design of algorithms for tasks like parsing, as it reduces the complexity of the rules that need to be handled. It is particularly crucial for algorithms like the CYK (Cocke-Younger-Kasami) algorithm, which determines whether a given string can be generated by a specific grammar. The standardization to two specific types of production rules in CNF allows for more streamlined and efficient computational processes.





### Grammar

```python
    class Grammar:
    def __init__(self):
self.s = ['S']
        self.vn = 
        self.vt = 
        self.p = [
            
        ]
        self.dic = {

```

Here I initialize the class and its components that we will need to analyze and modify, which will include the non
terminal, terminal, the dictionary that will come into play eventually, and the products that we will have to modify
according to the stated rules.


### Remove_Null

```python    
    def remove_null(self):
        x = 0
        while x in range(len(self.p)):
            culprit = self.p[x]
            if culprit[2] == 'e':
                trigger = culprit[0]
                del self.p[x]
                el = 0
```

A snippet of the function that removes epsilons, which I have noted with the letter e. After finding such products,
it looks at the letter that leads to the product, removing that specific one completely. Afterwards, it looks throughout
the product to remove all instances of that letter in the entire thing. When it finds multiple occurrences in the same
object, it removes them one by one without affecting the original string, and adds them to the product rules. After 
that, it checks if there are more than one occurrences, and if they are, it removes all instances of the related letter
and adds it to our rules


### Unit_productions

```python
                    def unit_production(self):
        replace = [
            (),
        ]
        for element in self.p:
            if element[0] in self.vn and element[2] in self.vn and len(element[2]+element[1]) == 1:
                replace.append((element[0], element[2]))
```
In the `unit_production` method of our class, we manage modifications to our production rules, which are stored in `self.p`. The method begins by identifying rules that need replacement through a filtering process; specifically, it collects tuples where both the first and third elements are non-terminal symbols from `self.p` and the concatenation of the second and third elements yields a string of length one. These tuples are stored in the `replace` list after removing an initially added empty tuple.

We then create a temporary copy of `self.p` and an `addition` list to store new rules. For each tuple in `replace`, corresponding rules from the copy that match certain criteria (matching initial elements) are modified and added to `addition`. Post modification, we clean the `addition` list by removing its initial empty tuple.

The method proceeds to refine `self.p` by removing rules that fulfill the initial filter criteria, then extends it with new rules from `addition`, followed by sorting the entire list. Each rule is then printed in a formatted style to aid visualization, and we conclude by outputting the total count of the production rules. This process helps maintain and transform our grammar rules efficiently, crucial for parsing tasks or grammar analysis in computational linguistics.
### Unproductive
```python
    def unproductive(self):
        trash = ["",]
        big_string = ""
        for element in self.p:
            big_string = big_string + element[0]
        for element in self.p:
```
In the unproductive method of our class, we focus on identifying and removing unproductive rules from our production rules set self.p. The method starts by initializing a list trash to keep track of symbols that are considered unproductive. We then concatenate the first elements of all tuples in self.p into a single string, big_string.

The next step involves iterating through self.p to identify specific rules that may be unproductive. A rule is considered for unproductivity if its first element (presumably a non-terminal symbol) occurs only once in big_string and is also present in the third element of its own tuple. If these conditions are met, we further examine the third element (a string) to count uppercase and lowercase letters. A rule is marked as unproductive and its first element is added to trash if it contains exactly one uppercase letter and at least one lowercase letter.

After compiling the trash list (and removing an initial empty string), we proceed to filter out the unproductive rules. We do this by iterating over self.p and deleting any rule where a symbol from trash appears either as the rule's symbol or within the rule's third element. This step involves careful iteration to avoid skipping elements due to list modification during iteration.

Finally, the method prints the remaining productive rules in a formatted manner and outputs the total count of these rules. This allows us to maintain a clean set of productive rules, essential for ensuring the efficiency and correctness of further processing in grammar-based systems.

### Final_touches
```python
    def chomsky_normal_form(self):
        # 5. Obtain CNF
        p5 = self.dic.copy()
        temp = {}
        vocabulary = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S',
                      'T', 'U', 'V', 'W', 'X', 'Y', 'Z']
        free_symbols = [v for v in vocabulary if v not in self.dic.keys()]
        for key, value in self.dic.items():
            for v in value:
```
The chomsky_normal_form function is designed to convert the production rules of a context-free grammar, stored in self.dic, into Chomsky Normal Form (CNF). This process involves ensuring that each production rule either produces two non-terminal symbols or a single terminal symbol, which are the essential conditions for CNF.

The function starts by copying the original dictionary of production rules (self.dic) into a new dictionary (p5). It also prepares a list of potential new non-terminal symbols (free_symbols) derived from the uppercase English alphabet, excluding those already used as keys in the dictionary.

For each production in the grammar, the function checks if it already conforms to CNF (productions that are either a single terminal or two consecutive non-terminals). If a production does not meet these criteria, it splits the production into two parts. The function then checks whether these substrings already correspond to new symbols in a temporary dictionary (temp). If not, it assigns new symbols from free_symbols.

For productions that are broken into two parts, new non-terminal symbols are assigned or reused from temp for each half of the original production. These symbols replace the original production in the dictionary, thereby modifying the grammar toward adherence to CNF.

This approach iteratively refines all rules of the grammar, ensuring that by the conclusion of the function, all rules either consist of exactly one terminal or two non-terminals, thus achieving the Chomsky Normal Form. This function plays a crucial role in simplifying grammar for more efficient parsing and processing in computational linguistics tasks.

### Results
```

```text
Given Expression: self.s = ['S']
        self.vn = ['A', 'B', 'C', 'S', 'D']
        self.vt = ['a', 'b', 'c', 'd']
        self.p = [
            ('S', '', 'AC'),
            ('S', 'b', 'A'),
            ('S', '', 'B'),
            ('S', 'a', 'A'),
            ('A', '', 'e'),
            ('A', 'a', 'S'),
            ('A', '', 'ABAb'),
            ('B', 'a', ''),
            ('B', '', 'AbSA'),
            ('C', '', 'abC'),
            ('D', '', 'AB'),
Chomski normal form: {'A': ['CD', 'EF', 'GD', 'GH', 'IJ'], 'B': ['EK', 'DL', 'HJ', 'HL', 'a'], 'S': ['EK', 'DL', 'HJ',
 'HL', 'a', 'a', 'IE', 'b', 'HE'], 'C': ['AB'], 'D': ['Ab'], 'E': ['A'], 'F': ['Bb'], 'G': ['B'], 'H': ['b'], 
 'I': ['a'], 'J': ['S'], 'K': ['bS'], 'L': ['SA']}

```

The transformation process elegantly unfolds as it translates complex, regex-like expressions into actionable codes and 
eventually into specific outputs, demonstrating a sophisticated mechanism of interpretation and generation. Initially, 
each expression undergoes a meticulous segmentation, breaking down into discernible parts that isolate unique patterns 
and symbols. This essential step ensures that each component, with its distinct characteristics‚Äîbe it a choice between 
characters, repetition, or conditional appearance‚Äîis individually addressed. Following this, a coding system assigns 
numerical values to these segments, a method that translates symbolic intricacies into a universally understandable 
numeric format. Such coding not only simplifies the interpretation process but also lays down a concrete foundation for
the subsequent generation phase. In this final step, the codes guide the construction of an output string that adheres 
to the original expression's rules, producing varied results like acEE, PRTWZZZ, or 124444436. This output generation, 
inherently flexible, can easily yield a multitude of possible strings, each conforming to the predefined constraints, 
showcasing the process's ability to encapsulate the complexity of regex-like expressions in a structured and 
comprehensible manner.
### Conclusion

This laboratory provided a practical and detailed exploration into the transformation of production rules into Chomsky Normal Form (CNF), a fundamental aspect of theoretical computer science and computational linguistics. Through the implementation and examination of functions like `unit_production` and `unproductive`, I gained hands-on experience in modifying and standardizing grammar rules according to CNF criteria. These functions specifically helped in eliminating unit productions and identifying unproductive rules, both crucial steps in the CNF conversion process.

The tasks challenged me to apply theoretical knowledge to actual code, enhancing my understanding of how grammars can be systematically transformed to simplify parsing and further processing. Each function underscored the importance of adhering to CNF rules‚Äîproducing either two non-terminals or a single terminal from a non-terminal‚Äîand how such structuring could significantly impact algorithm efficiency in language processing tasks. Overall, this laboratory was instrumental in reinforcing the concepts and applications of CNF in a clear and practical manner, making the abstract principles more tangible and comprehensible.